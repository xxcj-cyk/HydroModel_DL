"""
SHAPåˆ†æå™¨ç”¨äºLSTMæ¨¡å‹çš„ç‰¹å¾é‡è¦æ€§åˆ†æ

æ”¯æŒDeepExplainerï¼Œè®¡ç®—æ¯ä¸ªæ—¶é—´æ­¥æ¯ä¸ªç‰¹å¾çš„SHAPå€¼è´¡çŒ®åº¦
"""

import os
import numpy as np
import torch
import torch.nn as nn
import pandas as pd
from typing import Dict, List, Optional, Tuple, Union
import random
import warnings

# è¿‡æ»¤sklearnçš„ConvergenceWarningï¼ˆKernelExplainerå†…éƒ¨ä½¿ç”¨LARSç®—æ³•æ—¶ä¼šäº§ç”Ÿè¿™äº›è­¦å‘Šï¼‰
warnings.filterwarnings('ignore', category=UserWarning, module='sklearn.linear_model._least_angle')

try:
    import shap
    SHAP_AVAILABLE = True
except ImportError:
    SHAP_AVAILABLE = False
    print("è­¦å‘Š: shapåº“æœªå®‰è£…ï¼Œè¯·ä½¿ç”¨ pip install shap å®‰è£…")


class LSTMSHAPAnalyzer:
    """
    LSTMæ¨¡å‹çš„SHAPåˆ†æå™¨
    
    ç”¨äºè®¡ç®—LSTMæ¨¡å‹æ¯ä¸ªæ—¶é—´æ­¥æ¯ä¸ªç‰¹å¾çš„SHAPå€¼è´¡çŒ®åº¦
    """
    
    def __init__(
        self,
        model: nn.Module,
        background_data: np.ndarray,
        device: torch.device,
        explainer_type: str = "KernelExplainer",
        which_first_tensor: str = "sequence",
    ):
        """
        åˆå§‹åŒ–SHAPåˆ†æå™¨
        
        Parameters
        ----------
        model : nn.Module
            è®­ç»ƒå¥½çš„LSTMæ¨¡å‹
        background_data : np.ndarray
            èƒŒæ™¯æ•°æ®ï¼Œå½¢çŠ¶ä¸º (n_samples, seq_length, n_features)
        device : torch.device
            è®¡ç®—è®¾å¤‡ (CPUæˆ–GPU)
        explainer_type : str
            è§£é‡Šå™¨ç±»å‹ï¼Œå¯é€‰ï¼š
            - "GradientExplainer": ä¸“é—¨ä¸ºPyTorchè®¾è®¡ï¼ˆæ¨èï¼‰
            - "Explainer": ä½¿ç”¨SHAPæ–°APIï¼Œè‡ªåŠ¨é€‰æ‹©è§£é‡Šå™¨ï¼ˆæ¨èï¼‰
            - "DeepExplainer": æ—§APIï¼Œå¯èƒ½å°è¯•å¯¼å…¥TensorFlowï¼ˆä¸æ¨èç”¨äºPyTorchï¼‰
            - "KernelExplainer": é€šç”¨è§£é‡Šå™¨ï¼Œè¾ƒæ…¢ä½†ç¨³å®š
        which_first_tensor : str
            å¼ é‡æ ¼å¼ï¼Œ"sequence" è¡¨ç¤º (seq_len, batch, features)ï¼Œ"batch" è¡¨ç¤º (batch, seq_len, features)
        """
        if not SHAP_AVAILABLE:
            raise ImportError("shapåº“æœªå®‰è£…ï¼Œè¯·ä½¿ç”¨ pip install shap å®‰è£…")
        
        self.model = model
        self.device = device
        self.explainer_type = explainer_type
        self.which_first_tensor = which_first_tensor
        self.seq_first = which_first_tensor == "sequence"
        
        # å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        self.model.eval()
        
        # å¤„ç†DataParallelæ¨¡å‹
        if isinstance(model, nn.DataParallel):
            self.model_core = model.module
        else:
            self.model_core = model
        
        # å‡†å¤‡èƒŒæ™¯æ•°æ®
        self.background_data = self._prepare_background_data(background_data)
        
        # åˆ›å»ºSHAPè§£é‡Šå™¨
        self.explainer = self._create_explainer()
    
    def _prepare_background_data(self, background_data: np.ndarray) -> torch.Tensor:
        """
        å‡†å¤‡èƒŒæ™¯æ•°æ®ï¼Œè½¬æ¢ä¸ºæ¨¡å‹éœ€è¦çš„æ ¼å¼
        
        Parameters
        ----------
        background_data : np.ndarray
            èƒŒæ™¯æ•°æ®ï¼Œå½¢çŠ¶ä¸º (n_samples, seq_length, n_features)
        
        Returns
        -------
        torch.Tensor
            è½¬æ¢åçš„èƒŒæ™¯æ•°æ®
        """
        # è½¬æ¢ä¸ºtorch tensor
        bg_tensor = torch.from_numpy(background_data).float()
        
        # æ ¹æ®æ¨¡å‹è¾“å…¥æ ¼å¼è½¬æ¢
        if self.seq_first:
            # å¦‚æœæ˜¯sequence firstï¼Œéœ€è¦è½¬æ¢ä¸º (seq_len, batch, features)
            # èƒŒæ™¯æ•°æ®æ˜¯ (n_samples, seq_length, n_features)
            # éœ€è¦è½¬æ¢ä¸º (seq_length, n_samples, n_features)
            bg_tensor = bg_tensor.permute(1, 0, 2)
        
        return bg_tensor.to(self.device)
    
    def _create_explainer(self):
        """
        åˆ›å»ºSHAPè§£é‡Šå™¨
        
        Returns
        -------
        shap.Explainer
            SHAPè§£é‡Šå™¨å¯¹è±¡
        """
        # å®šä¹‰æ¨¡å‹åŒ…è£…å‡½æ•°ï¼Œç”¨äºSHAP
        # å¯¹äºæ—¶åºæ¨¡å‹ï¼Œæˆ‘ä»¬è¿”å›æ‰€æœ‰æ—¶é—´æ­¥çš„è¾“å‡ºï¼Œå±•å¹³ä»¥ä¾¿SHAPè®¡ç®—
        def model_wrapper(x):
            """
            æ¨¡å‹åŒ…è£…å‡½æ•°ï¼Œå°†è¾“å…¥è½¬æ¢ä¸ºæ¨¡å‹éœ€è¦çš„æ ¼å¼
            
            Parameters
            ----------
            x : torch.Tensor
                è¾“å…¥æ•°æ®ï¼Œå½¢çŠ¶ä¸º (batch, seq_len, features) æˆ– (seq_len, batch, features)
            
            Returns
            -------
            torch.Tensor
                æ¨¡å‹è¾“å‡ºï¼Œå½¢çŠ¶ä¸º (batch, seq_len * output_size)
                è¿™æ ·SHAPå¯ä»¥ä¸ºæ¯ä¸ªæ—¶é—´æ­¥çš„æ¯ä¸ªç‰¹å¾è®¡ç®—è´¡çŒ®
            """
            self.model.eval()
            with torch.no_grad():
                # ç¡®ä¿è¾“å…¥æ˜¯torch tensor
                if isinstance(x, np.ndarray):
                    x_tensor = torch.from_numpy(x).float()
                else:
                    x_tensor = x.float()
                
                # å¤„ç†è¾“å…¥å½¢çŠ¶
                if x_tensor.ndim == 2:
                    # å¦‚æœæ˜¯å±•å¹³çš„æ•°æ®ï¼Œéœ€è¦reshape
                    # å‡è®¾èƒŒæ™¯æ•°æ®çš„å½¢çŠ¶
                    n_samples = x_tensor.shape[0]
                    seq_length = self.background_data.shape[0] if self.seq_first else self.background_data.shape[1]
                    n_features = self.background_data.shape[2] if self.seq_first else self.background_data.shape[2]
                    x_tensor = x_tensor.view(n_samples, seq_length, n_features)
                
                # è½¬æ¢ä¸ºæ¨¡å‹éœ€è¦çš„æ ¼å¼
                if self.seq_first:
                    # sequence first: (seq_len, batch, features)
                    x_tensor = x_tensor.permute(1, 0, 2)
                else:
                    # batch first: (batch, seq_len, features)
                    pass
                
                x_tensor = x_tensor.to(self.device)
                
                # å‰å‘ä¼ æ’­
                output = self.model_core(x_tensor)
                
                # å¤„ç†è¾“å‡ºæ ¼å¼
                if self.seq_first:
                    # å¦‚æœæ˜¯sequence firstï¼Œè¾“å‡ºä¹Ÿæ˜¯ (seq_len, batch, output_size)
                    # è½¬æ¢ä¸º (batch, seq_len, output_size)
                    output = output.permute(1, 0, 2)
                
                # å±•å¹³è¾“å‡º: (batch, seq_len * output_size)
                # è¿™æ ·SHAPå¯ä»¥ä¸ºæ¯ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºè®¡ç®—æ¯ä¸ªæ—¶é—´æ­¥è¾“å…¥çš„è´¡çŒ®
                batch_size = output.shape[0]
                output_flat = output.reshape(batch_size, -1)
                
                # è¿”å›numpyæ•°ç»„ï¼Œè€Œä¸æ˜¯Tensorï¼ˆæŸäº›explaineréœ€è¦numpyæ•°ç»„ï¼‰
                # ä½¿ç”¨detach()ç¡®ä¿æ²¡æœ‰gradientä¿¡æ¯
                return output_flat.detach().cpu().numpy()
        
        # å‡†å¤‡èƒŒæ™¯æ•°æ®ç”¨äºSHAP
        bg_for_shap = self.background_data
        
        # å‡†å¤‡KernelExplainerçš„å¤‡é€‰æ–¹æ¡ˆï¼ˆä¸ä¾èµ–TensorFlowï¼‰
        def get_kernel_explainer():
            """è·å–KernelExplainerä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ"""
            bg_numpy = self.background_data.detach().cpu().numpy()
            if self.seq_first:
                bg_numpy = bg_numpy.transpose(1, 0, 2)
            bg_flat = bg_numpy.reshape(bg_numpy.shape[0], -1)
            
            def model_wrapper_numpy(x):
                self.model.eval()
                with torch.no_grad():
                    # ç¡®ä¿è¾“å…¥æ˜¯numpyæ•°ç»„
                    if isinstance(x, torch.Tensor):
                        x_np = x.detach().cpu().numpy()
                    else:
                        x_np = np.asarray(x)
                    
                    x_tensor = torch.from_numpy(x_np).float()
                    
                    # è·å–é¢„æœŸçš„å½¢çŠ¶ä¿¡æ¯
                    if self.seq_first:
                        seq_length = self.background_data.shape[0]
                        n_features = self.background_data.shape[2]
                    else:
                        seq_length = self.background_data.shape[1]
                        n_features = self.background_data.shape[2]
                    
                    expected_flat_size = seq_length * n_features
                    original_shape = x_np.shape
                    
                    # å¤„ç†è¾“å…¥å½¢çŠ¶ï¼ˆä¸ä¸»åˆ†æ”¯ä¸­çš„é€»è¾‘ä¸€è‡´ï¼‰
                    if x_tensor.ndim == 2:
                        if x_tensor.shape[1] == expected_flat_size:
                            n_samples = x_tensor.shape[0]
                        else:
                            x_flat = x_tensor.flatten()
                            total_elements = x_flat.numel()
                            n_samples = total_elements // expected_flat_size
                            remainder = total_elements % expected_flat_size
                            if remainder != 0:
                                if total_elements % n_features == 0:
                                    n_samples_single_step = total_elements // n_features
                                    raise ValueError(
                                        f"è¾“å…¥å¤§å°ä¸åŒ¹é…: è¾“å…¥å½¢çŠ¶ {original_shape}, æ€»å…ƒç´ æ•° {total_elements}. "
                                        f"æœŸæœ›æ¯æ ·æœ¬ {expected_flat_size} (seq_length={seq_length} * n_features={n_features}), "
                                        f"ä½†å¾—åˆ°çš„æ•°æ®å¯èƒ½æ˜¯ {n_samples_single_step} ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬ {n_features} ä¸ªç‰¹å¾ "
                                        f"(åªåŒ…å«æœ€åä¸€ä¸ªæ—¶é—´æ­¥?)."
                                    )
                                else:
                                    raise ValueError(
                                        f"è¾“å…¥å¤§å°ä¸åŒ¹é…: è¾“å…¥å½¢çŠ¶ {original_shape}, æ€»å…ƒç´ æ•° {total_elements} ä¸èƒ½è¢« "
                                        f"{expected_flat_size} æ•´é™¤."
                                    )
                            x_tensor = x_flat.view(n_samples, expected_flat_size)
                    elif x_tensor.ndim == 1:
                        if x_tensor.shape[0] != expected_flat_size:
                            raise ValueError(
                                f"è¾“å…¥å¤§å°ä¸åŒ¹é…: æœŸæœ› {expected_flat_size}, ä½†å¾—åˆ° {x_tensor.shape[0]}. "
                                f"è¾“å…¥å½¢çŠ¶: {original_shape}"
                            )
                        x_tensor = x_tensor.unsqueeze(0)
                        n_samples = 1
                    else:
                        x_flat = x_tensor.flatten()
                        total_elements = x_flat.numel()
                        n_samples = total_elements // expected_flat_size
                        remainder = total_elements % expected_flat_size
                        if remainder != 0:
                            raise ValueError(
                                f"è¾“å…¥å¤§å°ä¸åŒ¹é…: è¾“å…¥å½¢çŠ¶ {original_shape}, æ€»å…ƒç´ æ•° {total_elements} ä¸èƒ½è¢« "
                                f"{expected_flat_size} æ•´é™¤."
                            )
                        x_tensor = x_flat.view(n_samples, expected_flat_size)
                    
                    # Reshapeä¸º (n_samples, seq_length, n_features)
                    x_tensor = x_tensor.view(n_samples, seq_length, n_features)
                    
                    # è½¬æ¢ä¸ºæ¨¡å‹éœ€è¦çš„æ ¼å¼
                    if self.seq_first:
                        x_tensor = x_tensor.permute(1, 0, 2)
                    
                    x_tensor = x_tensor.to(self.device)
                    output = self.model_core(x_tensor)
                    
                    if self.seq_first:
                        output = output.permute(1, 0, 2)
                    if output.ndim == 3:
                        output = output.reshape(output.shape[0], -1)
                    # ä½¿ç”¨detach()ç¡®ä¿æ²¡æœ‰gradientä¿¡æ¯
                    return output.detach().cpu().numpy()
            
            return shap.KernelExplainer(model_wrapper_numpy, bg_flat)
        
        if self.explainer_type == "Explainer":
            # ä½¿ç”¨SHAPæ–°APIï¼Œæ˜ç¡®æŒ‡å®šä½¿ç”¨KernelExplainerç®—æ³•
            # å› ä¸ºPermutationExplainerå¯èƒ½ä¸å…¼å®¹æˆ‘ä»¬çš„æ¨¡å‹åŒ…è£…å‡½æ•°
            try:
                # å°è¯•ä½¿ç”¨KernelExplainerä½œä¸ºç®—æ³•
                bg_numpy = self.background_data.detach().cpu().numpy()
                if self.seq_first:
                    bg_numpy = bg_numpy.transpose(1, 0, 2)
                bg_flat = bg_numpy.reshape(bg_numpy.shape[0], -1)
                
                def model_wrapper_flat(x):
                    """å±•å¹³è¾“å…¥çš„æ¨¡å‹åŒ…è£…å‡½æ•°"""
                    self.model.eval()
                    with torch.no_grad():
                        x_tensor = torch.from_numpy(x).float()
                        if self.seq_first:
                            n_samples = x_tensor.shape[0]
                            seq_length = self.background_data.shape[0]
                            n_features = self.background_data.shape[2]
                            x_tensor = x_tensor.view(n_samples, seq_length, n_features)
                            x_tensor = x_tensor.permute(1, 0, 2)
                        x_tensor = x_tensor.to(self.device)
                        output = self.model_core(x_tensor)
                        if self.seq_first:
                            output = output.permute(1, 0, 2)
                        if output.ndim == 3:
                            output = output.reshape(output.shape[0], -1)
                        # ä½¿ç”¨detach()ç¡®ä¿æ²¡æœ‰gradientä¿¡æ¯
                        return output.detach().cpu().numpy()
                
                # ä½¿ç”¨KernelExplainerç®—æ³•
                explainer = shap.Explainer(model_wrapper_flat, bg_flat, algorithm="permutation")
                print("ä½¿ç”¨Explainerï¼ˆKernelç®—æ³•ï¼‰")
            except Exception as e:
                print(f"Explaineråˆå§‹åŒ–å¤±è´¥ï¼Œå›é€€åˆ°KernelExplainer: {e}")
                explainer = get_kernel_explainer()
                self.explainer_type = "KernelExplainer"
                print("å·²åˆ‡æ¢åˆ°KernelExplainerï¼ˆä¸ä¾èµ–TensorFlowï¼‰")
        
        elif self.explainer_type == "GradientExplainer":
            # GradientExplainerå¯èƒ½ä¹Ÿéœ€è¦TensorFlowï¼Œå°è¯•åå›é€€
            try:
                explainer = shap.GradientExplainer(model_wrapper, bg_for_shap)
                print("ä½¿ç”¨GradientExplainer")
            except (ImportError, ModuleNotFoundError) as e:
                if "tensorflow" in str(e).lower() or "tf" in str(e).lower():
                    print(f"GradientExplaineréœ€è¦TensorFlowï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°KernelExplainer: {e}")
                    explainer = get_kernel_explainer()
                    self.explainer_type = "KernelExplainer"
                    print("å·²åˆ‡æ¢åˆ°KernelExplainerï¼ˆä¸ä¾èµ–TensorFlowï¼‰")
                else:
                    raise RuntimeError(f"GradientExplaineråˆå§‹åŒ–å¤±è´¥: {e}")
        
        elif self.explainer_type == "DeepExplainer":
            # DeepExplainerä¼šå°è¯•å¯¼å…¥TensorFlow
            print("è­¦å‘Š: DeepExplainerå¯èƒ½å°è¯•å¯¼å…¥TensorFlow")
            try:
                explainer = shap.DeepExplainer(model_wrapper, bg_for_shap)
                print("DeepExplaineråˆå§‹åŒ–æˆåŠŸ")
            except (ImportError, ModuleNotFoundError) as e:
                if "tensorflow" in str(e).lower() or "tf" in str(e).lower():
                    print(f"DeepExplaineréœ€è¦TensorFlowï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°KernelExplainer: {e}")
                    explainer = get_kernel_explainer()
                    self.explainer_type = "KernelExplainer"
                    print("å·²åˆ‡æ¢åˆ°KernelExplainerï¼ˆä¸ä¾èµ–TensorFlowï¼‰")
                else:
                    raise RuntimeError(f"DeepExplaineråˆå§‹åŒ–å¤±è´¥: {e}")
        elif self.explainer_type == "KernelExplainer":
            # å¯¹äºKernelExplainerï¼Œéœ€è¦å±•å¹³æ•°æ®
            bg_numpy = self.background_data.detach().cpu().numpy()
            if self.seq_first:
                # ä» (seq_len, batch, features) è½¬æ¢ä¸º (batch, seq_len, features)
                bg_numpy = bg_numpy.transpose(1, 0, 2)
            # å±•å¹³ä¸º (batch, seq_len * features)
            bg_flat = bg_numpy.reshape(bg_numpy.shape[0], -1)
            
            # KernelExplaineréœ€è¦numpyåŒ…è£…å‡½æ•°
            def model_wrapper_numpy(x):
                self.model.eval()
                with torch.no_grad():
                    # ç¡®ä¿è¾“å…¥æ˜¯numpyæ•°ç»„
                    if isinstance(x, torch.Tensor):
                        x_np = x.detach().cpu().numpy()
                    else:
                        x_np = np.asarray(x)
                    
                    x_tensor = torch.from_numpy(x_np).float()
                    
                    # è·å–é¢„æœŸçš„å½¢çŠ¶ä¿¡æ¯
                    if self.seq_first:
                        # èƒŒæ™¯æ•°æ®å½¢çŠ¶: (seq_len, batch, features)
                        seq_length = self.background_data.shape[0]
                        n_features = self.background_data.shape[2]
                    else:
                        # èƒŒæ™¯æ•°æ®å½¢çŠ¶: (batch, seq_len, features)
                        seq_length = self.background_data.shape[1]
                        n_features = self.background_data.shape[2]
                    
                    expected_flat_size = seq_length * n_features
                    
                    # è°ƒè¯•ä¿¡æ¯ï¼ˆä»…åœ¨å‡ºé”™æ—¶æ‰“å°ï¼‰
                    original_shape = x_np.shape
                    
                    # å¤„ç†è¾“å…¥å½¢çŠ¶
                    # KernelExplainerä¼ å…¥çš„xåº”è¯¥æ˜¯ (n_samples, n_features_flat) æˆ– (n_features_flat,)
                    original_shape = x_np.shape
                    
                    # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯æ ‡å‡†çš„2Dæ ¼å¼
                    if x_tensor.ndim == 2:
                        # æ ‡å‡†æ ¼å¼: (n_samples, n_features_flat)
                        if x_tensor.shape[1] == expected_flat_size:
                            # æ ¼å¼æ­£ç¡®
                            n_samples = x_tensor.shape[0]
                        else:
                            # ç‰¹å¾æ•°ä¸åŒ¹é…ï¼Œå¯èƒ½æ˜¯å…¶ä»–æ ¼å¼
                            # å°è¯•å±•å¹³å¹¶é‡æ–°è®¡ç®—
                            x_flat = x_tensor.flatten()
                            total_elements = x_flat.numel()
                            n_samples = total_elements // expected_flat_size
                            remainder = total_elements % expected_flat_size
                            
                            if remainder != 0:
                                # å°è¯•æ£€æŸ¥æ˜¯å¦æ˜¯åªä¼ å…¥äº†æœ€åä¸€ä¸ªæ—¶é—´æ­¥
                                if total_elements % n_features == 0:
                                    # å¯èƒ½æ˜¯åªä¼ å…¥äº†æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„æ•°æ®
                                    n_samples_single_step = total_elements // n_features
                                    raise ValueError(
                                        f"è¾“å…¥å¤§å°ä¸åŒ¹é…: è¾“å…¥å½¢çŠ¶ {original_shape}, æ€»å…ƒç´ æ•° {total_elements}. "
                                        f"æœŸæœ›æ¯æ ·æœ¬ {expected_flat_size} (seq_length={seq_length} * n_features={n_features}), "
                                        f"ä½†å¾—åˆ°çš„æ•°æ®å¯èƒ½æ˜¯ {n_samples_single_step} ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬ {n_features} ä¸ªç‰¹å¾ "
                                        f"(åªåŒ…å«æœ€åä¸€ä¸ªæ—¶é—´æ­¥?). "
                                        f"è¿™å¯èƒ½æ„å‘³ç€ KernelExplainer ä¼ å…¥çš„æ•°æ®æ ¼å¼ä¸èƒŒæ™¯æ•°æ®æ ¼å¼ä¸ä¸€è‡´ã€‚"
                                    )
                                else:
                                    raise ValueError(
                                        f"è¾“å…¥å¤§å°ä¸åŒ¹é…: è¾“å…¥å½¢çŠ¶ {original_shape}, æ€»å…ƒç´ æ•° {total_elements} ä¸èƒ½è¢« "
                                        f"{expected_flat_size} (seq_length={seq_length} * n_features={n_features}) æ•´é™¤. "
                                        f"è¿™å¯èƒ½æ„å‘³ç€æ•°æ®æ ¼å¼ä¸æ­£ç¡®ã€‚"
                                    )
                            x_tensor = x_flat.view(n_samples, expected_flat_size)
                    elif x_tensor.ndim == 1:
                        # å•ä¸ªæ ·æœ¬: (n_features_flat,)
                        if x_tensor.shape[0] != expected_flat_size:
                            raise ValueError(
                                f"è¾“å…¥å¤§å°ä¸åŒ¹é…: æœŸæœ› {expected_flat_size} (seq_length={seq_length} * n_features={n_features}), "
                                f"ä½†å¾—åˆ° {x_tensor.shape[0]}. è¾“å…¥å½¢çŠ¶: {original_shape}"
                            )
                        x_tensor = x_tensor.unsqueeze(0)
                        n_samples = 1
                    else:
                        # å…¶ä»–å½¢çŠ¶ï¼Œå°è¯•å±•å¹³
                        x_flat = x_tensor.flatten()
                        total_elements = x_flat.numel()
                        n_samples = total_elements // expected_flat_size
                        remainder = total_elements % expected_flat_size
                        
                        if remainder != 0:
                            raise ValueError(
                                f"è¾“å…¥å¤§å°ä¸åŒ¹é…: è¾“å…¥å½¢çŠ¶ {original_shape}, æ€»å…ƒç´ æ•° {total_elements} ä¸èƒ½è¢« "
                                f"{expected_flat_size} (seq_length={seq_length} * n_features={n_features}) æ•´é™¤. "
                                f"è¿™å¯èƒ½æ„å‘³ç€ KernelExplainer ä¼ å…¥çš„æ•°æ®æ ¼å¼ä¸èƒŒæ™¯æ•°æ®æ ¼å¼ä¸ä¸€è‡´ã€‚"
                            )
                        x_tensor = x_flat.view(n_samples, expected_flat_size)
                    
                    # Reshapeä¸º (n_samples, seq_length, n_features)
                    x_tensor = x_tensor.view(n_samples, seq_length, n_features)
                    
                    # è½¬æ¢ä¸ºæ¨¡å‹éœ€è¦çš„æ ¼å¼
                    if self.seq_first:
                        # sequence first: (seq_len, batch, features)
                        x_tensor = x_tensor.permute(1, 0, 2)
                    # else: batch first: (batch, seq_len, features) - å·²ç»æ˜¯æ­£ç¡®æ ¼å¼
                    
                    x_tensor = x_tensor.to(self.device)
                    output = self.model_core(x_tensor)
                    
                    # å¤„ç†è¾“å‡ºæ ¼å¼
                    if self.seq_first:
                        # å¦‚æœæ˜¯sequence firstï¼Œè¾“å‡ºä¹Ÿæ˜¯ (seq_len, batch, output_size)
                        # è½¬æ¢ä¸º (batch, seq_len, output_size)
                        output = output.permute(1, 0, 2)
                    
                    # å±•å¹³è¾“å‡ºä»¥ä¾¿SHAPè®¡ç®—: (batch, seq_len * output_size)
                    if output.ndim == 3:
                        output = output.reshape(output.shape[0], -1)
                    # ä½¿ç”¨detach()ç¡®ä¿æ²¡æœ‰gradientä¿¡æ¯
                    return output.detach().cpu().numpy()
            
            explainer = shap.KernelExplainer(model_wrapper_numpy, bg_flat)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„explainerç±»å‹: {self.explainer_type}")
        
        return explainer
    
    def explain(
        self,
        instances: np.ndarray,
        nsamples: Optional[int] = None,
        batch_size: Optional[int] = None,
    ) -> np.ndarray:
        """
        è®¡ç®—SHAPå€¼
        
        Parameters
        ----------
        instances : np.ndarray
            è¦è§£é‡Šçš„å®ä¾‹ï¼Œå½¢çŠ¶ä¸º (n_instances, seq_length, n_features)
        nsamples : int, optional
            é‡‡æ ·æ•°é‡ï¼ˆä»…ç”¨äºKernelExplainerï¼‰
        batch_size : int, optional
            æ‰¹å¤„ç†å¤§å°ï¼Œç”¨äºé¿å…å†…å­˜æº¢å‡ºã€‚å¦‚æœä¸ºNoneï¼Œå°†æ ¹æ®æ ·æœ¬æ•°å’Œç‰¹å¾æ•°è‡ªåŠ¨è®¾ç½®
            å»ºè®®å€¼ï¼š100-500ï¼ˆå–å†³äºGPUå†…å­˜ï¼‰
        
        Returns
        -------
        np.ndarray
            SHAPå€¼ï¼Œå½¢çŠ¶ä¸º (n_instances, seq_length, n_features, n_outputs)
        """
        # å‡†å¤‡å®ä¾‹æ•°æ®
        if isinstance(instances, np.ndarray):
            instances_tensor = torch.from_numpy(instances).float()
        else:
            instances_tensor = instances.float()
        
        # æ ¹æ®explainerç±»å‹è®¡ç®—SHAPå€¼
        if self.explainer_type == "KernelExplainer":
            # KernelExplaineréœ€è¦numpyæ•°ç»„ï¼Œä¸æ˜¯Tensor
            # å±•å¹³å®ä¾‹æ•°æ®
            # æ³¨æ„ï¼šinstances è¾“å…¥æ ¼å¼æ˜¯ (n_samples, seq_length, n_features)ï¼Œå·²ç»æ˜¯batch first
            if isinstance(instances_tensor, torch.Tensor):
                instances_numpy = instances_tensor.detach().cpu().numpy()
            else:
                instances_numpy = instances_tensor
            
            # è°ƒè¯•ä¿¡æ¯
            print(f"åŸå§‹instanceså½¢çŠ¶: {instances_numpy.shape}")
            
            # instances_numpy å½¢çŠ¶åº”è¯¥æ˜¯ (n_samples, seq_length, n_features)
            # ç¡®ä¿æ˜¯3Dæ•°ç»„
            if instances_numpy.ndim != 3:
                raise ValueError(
                    f"instancesåº”è¯¥æ˜¯3Dæ•°ç»„ (n_samples, seq_length, n_features), "
                    f"ä½†å¾—åˆ°å½¢çŠ¶: {instances_numpy.shape}"
                )
            
            n_samples, seq_length, n_features = instances_numpy.shape
            print(f"è§£æåçš„ç»´åº¦: n_samples={n_samples}, seq_length={seq_length}, n_features={n_features}")
            
            # ç›´æ¥reshapeä¸º (n_samples, seq_length * n_features)
            instances_flat = instances_numpy.reshape(n_samples, seq_length * n_features)
            
            # è®¡ç®—SHAPå€¼
            # æ³¨æ„ï¼šKernelExplainerå¯èƒ½å¾ˆæ…¢ï¼Œç‰¹åˆ«æ˜¯å¯¹äºå¤§é‡æ ·æœ¬
            print(f"æ­£åœ¨ä½¿ç”¨KernelExplainerè®¡ç®—SHAPå€¼ï¼ˆè¿™å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼‰...")
            print(f"ä¼ å…¥KernelExplainerçš„æ•°æ®å½¢çŠ¶: {instances_flat.shape}")
            print(f"æœŸæœ›æ¯æ ·æœ¬ç‰¹å¾æ•°: {instances_flat.shape[1]} (seq_length * n_features)")
            
            # è®¡ç®—é‡ä¼°ç®—
            total_features = instances_flat.shape[1]  # seq_length * n_features
            n_samples = instances_flat.shape[0]
            estimated_calls = n_samples * total_features * 2  # ç²—ç•¥ä¼°ç®—
            print(f"\nâš ï¸  è®¡ç®—é‡ä¼°ç®—:")
            print(f"   - æ ·æœ¬æ•°: {n_samples}")
            print(f"   - æ¯æ ·æœ¬ç‰¹å¾æ•°: {total_features}")
            print(f"   - é¢„è®¡æ¨¡å‹è°ƒç”¨æ¬¡æ•°: ~{estimated_calls:,} (å–å†³äºnsampleså‚æ•°)")
            print(f"   - é¢„è®¡è®¡ç®—æ—¶é—´: æ•°å°æ—¶åˆ°æ•°å¤©ï¼ˆå–å†³äºç¡¬ä»¶å’Œnsamplesè®¾ç½®ï¼‰")
            print(f"\nğŸ’¡ å»ºè®®: å¦‚æœè®¡ç®—æ—¶é—´è¿‡é•¿ï¼Œè¯·è€ƒè™‘:")
            print(f"   1. ä½¿ç”¨ MAX_INSTANCES_FOR_SHAP å‚æ•°é™åˆ¶æ ·æœ¬æ•°é‡ï¼ˆå¦‚100-1000ï¼‰")
            print(f"   2. è®¾ç½®è¾ƒå°çš„ nsamples å‚æ•°ï¼ˆå¦‚100-500ï¼‰ä»¥å‡å°‘è®¡ç®—é‡")
            print(f"   3. åˆ†æ‰¹å¤„ç†æ ·æœ¬ï¼Œæ¯æ¬¡å¤„ç†ä¸€éƒ¨åˆ†\n")
            
            # é™åˆ¶æ ·æœ¬æ•°é‡ä»¥é¿å…è®¡ç®—æ—¶é—´è¿‡é•¿ï¼ˆå¯é€‰ï¼‰
            # å¦‚æœæ ·æœ¬å¤ªå¤šï¼Œå¯ä»¥å…ˆæµ‹è¯•å°‘é‡æ ·æœ¬
            max_samples_for_test = None  # è®¾ç½®ä¸ºNoneè¡¨ç¤ºå¤„ç†æ‰€æœ‰æ ·æœ¬
            if max_samples_for_test is not None and instances_flat.shape[0] > max_samples_for_test:
                print(f"è­¦å‘Š: æ ·æœ¬æ•°é‡ {instances_flat.shape[0]} å¾ˆå¤§ï¼Œåªå¤„ç†å‰ {max_samples_for_test} ä¸ªæ ·æœ¬è¿›è¡Œæµ‹è¯•")
                instances_flat = instances_flat[:max_samples_for_test]
                n_samples = instances_flat.shape[0]
            
            # è®¾ç½®é»˜è®¤çš„nsampleså€¼
            if nsamples is None:
                default_nsamples = 100
                print(f"âš ï¸  æœªæŒ‡å®š nsamples å‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼ {default_nsamples} ä»¥å‡å°‘è®¡ç®—æ—¶é—´")
                print(f"   å¦‚éœ€æ›´é«˜ç²¾åº¦ï¼Œå¯ä»¥åœ¨è°ƒç”¨ explain() æ—¶è®¾ç½® nsamples å‚æ•°ï¼ˆå¦‚ 500 æˆ– 1000ï¼‰")
                nsamples = default_nsamples
            else:
                print(f"ä½¿ç”¨ nsamples={nsamples} è¿›è¡Œè®¡ç®—ï¼ˆæ¯ä¸ªæ ·æœ¬çš„è®¡ç®—æ¬¡æ•°ï¼‰")
            
            # è‡ªåŠ¨è®¾ç½®æ‰¹å¤„ç†å¤§å°ä»¥é¿å…å†…å­˜æº¢å‡º
            # æ ¹æ®ç‰¹å¾æ•°å’ŒGPUå†…å­˜ä¼°ç®—åˆé€‚çš„æ‰¹å¤„ç†å¤§å°
            if batch_size is None:
                # å¯¹äºå¤§é‡ç‰¹å¾ï¼ˆå¦‚ 14328ï¼‰ï¼Œä½¿ç”¨è¾ƒå°çš„æ‰¹å¤„ç†å¤§å°
                if total_features > 10000:
                    batch_size = 50  # å¯¹äºå¤§é‡ç‰¹å¾ï¼Œä½¿ç”¨å¾ˆå°çš„æ‰¹å¤„ç†
                elif total_features > 5000:
                    batch_size = 100
                elif total_features > 1000:
                    batch_size = 200
                else:
                    batch_size = 500
                
                # å¦‚æœæ ·æœ¬æ•°è¾ƒå°‘ï¼Œä¸éœ€è¦æ‰¹å¤„ç†
                if n_samples <= batch_size:
                    batch_size = None
            
            # åˆ†æ‰¹å¤„ç†ä»¥é¿å…å†…å­˜æº¢å‡º
            if batch_size is not None and n_samples > batch_size:
                print(f"\nğŸ“¦ ä½¿ç”¨æ‰¹å¤„ç†æ¨¡å¼ï¼Œæ‰¹å¤§å°: {batch_size}")
                print(f"   å°† {n_samples} ä¸ªæ ·æœ¬åˆ†æˆ {int(np.ceil(n_samples / batch_size))} æ‰¹å¤„ç†\n")
                
                all_shap_values = []
                n_batches = int(np.ceil(n_samples / batch_size))
                
                for i in range(n_batches):
                    start_idx = i * batch_size
                    end_idx = min((i + 1) * batch_size, n_samples)
                    batch_instances = instances_flat[start_idx:end_idx]
                    
                    print(f"å¤„ç†ç¬¬ {i+1}/{n_batches} æ‰¹ (æ ·æœ¬ {start_idx+1}-{end_idx})...")
                    
                    # è®¡ç®—å½“å‰æ‰¹çš„SHAPå€¼
                    batch_shap_values = self.explainer.shap_values(batch_instances, nsamples=nsamples)
                    
                    # å¤„ç†SHAPå€¼æ ¼å¼
                    if isinstance(batch_shap_values, list):
                        batch_shap_values = np.array(batch_shap_values)
                        if batch_shap_values.ndim == 2:
                            # å•è¾“å‡º: (n_instances, n_features_flat)
                            all_shap_values.append(batch_shap_values)
                        else:
                            # å¤šè¾“å‡º: (n_outputs, n_instances, n_features_flat)
                            batch_shap_values = batch_shap_values.transpose(1, 0, 2)
                            all_shap_values.append(batch_shap_values)
                    else:
                        # ç¡®ä¿æ˜¯numpyæ•°ç»„
                        if not isinstance(batch_shap_values, np.ndarray):
                            batch_shap_values = np.array(batch_shap_values)
                        all_shap_values.append(batch_shap_values)
                    
                    # æ‰“å°å½“å‰æ‰¹çš„å½¢çŠ¶ç”¨äºè°ƒè¯•
                    if isinstance(all_shap_values[-1], np.ndarray):
                        print(f"   å½“å‰æ‰¹SHAPå€¼å½¢çŠ¶: {all_shap_values[-1].shape}")
                    
                    # æ¸…ç†GPUç¼“å­˜
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                    
                    print(f"   ç¬¬ {i+1} æ‰¹å®Œæˆ\n")
                
                # åˆå¹¶æ‰€æœ‰æ‰¹çš„SHAPå€¼
                print(f"æ­£åœ¨åˆå¹¶ {len(all_shap_values)} æ‰¹çš„SHAPå€¼...")
                # æ£€æŸ¥æ‰€æœ‰æ‰¹çš„å½¢çŠ¶æ˜¯å¦ä¸€è‡´
                if len(all_shap_values) > 0:
                    first_shape = all_shap_values[0].shape
                    print(f"ç¬¬ä¸€æ‰¹å½¢çŠ¶: {first_shape}")
                    for i, batch_shap in enumerate(all_shap_values[1:], 1):
                        if batch_shap.shape != first_shape[1:]:  # å¿½ç•¥ç¬¬ä¸€ä¸ªç»´åº¦ï¼ˆæ ·æœ¬æ•°ï¼‰
                            print(f"è­¦å‘Š: ç¬¬ {i+1} æ‰¹å½¢çŠ¶ {batch_shap.shape} ä¸ç¬¬ä¸€æ‰¹å½¢çŠ¶ä¸ä¸€è‡´")
                
                # æ ¹æ®ç»´åº¦ç¡®å®šåˆå¹¶çš„axis
                if len(all_shap_values) > 0:
                    if all_shap_values[0].ndim == 2:
                        # 2D: (n_instances, n_features_flat)ï¼Œæ²¿axis=0åˆå¹¶
                        shap_values = np.concatenate(all_shap_values, axis=0)
                    elif all_shap_values[0].ndim == 3:
                        # 3D: (n_instances, n_outputs, n_features_flat)ï¼Œæ²¿axis=0åˆå¹¶
                        shap_values = np.concatenate(all_shap_values, axis=0)
                    else:
                        raise ValueError(f"æ„å¤–çš„SHAPå€¼ç»´åº¦: {all_shap_values[0].ndim}")
                
                print(f"åˆå¹¶åSHAPå€¼å½¢çŠ¶: {shap_values.shape}")
            else:
                # ä¸ä½¿ç”¨æ‰¹å¤„ç†ï¼Œä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰æ ·æœ¬
                print(f"å¼€å§‹è®¡ç®—...ï¼ˆè¿™å¯èƒ½éœ€è¦å¾ˆé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼‰\n")
                shap_values = self.explainer.shap_values(instances_flat, nsamples=nsamples)
            
            # å¤„ç†SHAPå€¼æ ¼å¼ï¼ˆæ— è®ºæ˜¯å¦åˆ†æ‰¹å¤„ç†ï¼Œéƒ½éœ€è¦è¿™ä¸€æ­¥ï¼‰
            if isinstance(shap_values, list):
                # å¤šè¾“å‡ºæƒ…å†µ: list of arrays, each shape (n_instances, n_features_flat)
                shap_values = np.array(shap_values)  # (n_outputs, n_instances, n_features_flat)
                shap_values = shap_values.transpose(1, 0, 2)  # (n_instances, n_outputs, n_features_flat)
            
            # æ¢å¤åŸå§‹å½¢çŠ¶
            # æ³¨æ„ï¼šå®é™…å¤„ç†çš„æ ·æœ¬æ•°å¯èƒ½ä¸instances_numpyä¸åŒï¼ˆå¦‚æœä½¿ç”¨äº†max_samples_for_testï¼‰
            actual_n_instances = shap_values.shape[0]
            seq_length = instances_numpy.shape[1]
            n_features = instances_numpy.shape[2]
            
            print(f"\nå‡†å¤‡reshape SHAPå€¼:")
            print(f"  å®é™…æ ·æœ¬æ•°: {actual_n_instances}")
            print(f"  æ—¶é—´æ­¥æ•°: {seq_length}")
            print(f"  ç‰¹å¾æ•°: {n_features}")
            print(f"  SHAPå€¼å½“å‰å½¢çŠ¶: {shap_values.shape}")
            print(f"  SHAPå€¼ç»´åº¦æ•°: {shap_values.ndim}")
            
            # è·å–è¾“å‡ºæ•°é‡
            if shap_values.ndim == 2:
                # å•è¾“å‡º: (n_instances, n_features_flat)
                n_outputs = 1
                n_features_flat = shap_values.shape[1]
                expected_flat = seq_length * n_features
                
                print(f"  å•è¾“å‡ºæ¨¡å¼")
                print(f"  å±•å¹³ç‰¹å¾æ•°: {n_features_flat}, æœŸæœ›: {expected_flat}")
                
                if n_features_flat != expected_flat:
                    raise ValueError(
                        f"SHAPå€¼ç‰¹å¾æ•°ä¸åŒ¹é…: å®é™… {n_features_flat}, æœŸæœ› {expected_flat} "
                        f"(seq_length={seq_length} * n_features={n_features})"
                    )
                
                shap_values = shap_values.reshape(actual_n_instances, seq_length, n_features, n_outputs)
            elif shap_values.ndim == 3:
                # KernelExplainerå¯¹äºå¤šè¾“å‡ºæ¨¡å‹ï¼Œè¿”å›å½¢çŠ¶å¯èƒ½æ˜¯:
                # 1. (n_instances, n_outputs, n_features_flat) - æ ‡å‡†æ ¼å¼
                # 2. (n_instances, n_features_flat, n_outputs) - KernelExplainerçš„ç‰¹æ®Šæ ¼å¼
                
                dim1, dim2, dim3 = shap_values.shape[0], shap_values.shape[1], shap_values.shape[2]
                expected_flat = seq_length * n_features
                
                print(f"  3ç»´SHAPå€¼ï¼Œå½¢çŠ¶: {shap_values.shape}")
                
                # åˆ¤æ–­æ˜¯å“ªç§æ ¼å¼
                if dim2 == expected_flat and dim3 == seq_length:
                    # æ ¼å¼2: (n_instances, n_features_flat, n_outputs)
                    # å…¶ä¸­ n_features_flat = seq_length * n_features
                    #      n_outputs = seq_length (æ¯ä¸ªæ—¶é—´æ­¥ä¸€ä¸ªè¾“å‡º)
                    print(f"  æ£€æµ‹åˆ°KernelExplaineræ ¼å¼: (n_instances, n_features_flat, n_outputs)")
                    print(f"  å±•å¹³ç‰¹å¾æ•°: {dim2}, è¾“å‡ºæ•°(æ—¶é—´æ­¥æ•°): {dim3}")
                    
                    # shap_values[:, i, t] è¡¨ç¤ºç¬¬iä¸ªå±•å¹³ç‰¹å¾å¯¹ç¬¬tä¸ªè¾“å‡ºçš„è´¡çŒ®
                    # ç¬¬iä¸ªå±•å¹³ç‰¹å¾å¯¹åº”: æ—¶é—´æ­¥ i // n_features, ç‰¹å¾ i % n_features
                    # æˆ‘ä»¬éœ€è¦æå–: æ¯ä¸ªæ—¶é—´æ­¥çš„è¾“å…¥ç‰¹å¾å¯¹æ¯ä¸ªæ—¶é—´æ­¥è¾“å‡ºçš„è´¡çŒ®
                    # å¯¹äºæ—¶é—´åºåˆ—LSTMï¼Œé€šå¸¸æˆ‘ä»¬å…³å¿ƒ: æ¯ä¸ªæ—¶é—´æ­¥çš„è¾“å…¥å¯¹å½“å‰æ—¶é—´æ­¥è¾“å‡ºçš„è´¡çŒ®
                    # å³: shap_values[:, t*n_features:(t+1)*n_features, t]
                    
                    # åˆ›å»ºç»“æœæ•°ç»„: (n_instances, seq_length, n_features, 1)
                    # åªä¿ç•™æ¯ä¸ªæ—¶é—´æ­¥çš„è¾“å…¥å¯¹å½“å‰æ—¶é—´æ­¥è¾“å‡ºçš„è´¡çŒ®
                    shap_values_corrected = np.zeros((actual_n_instances, seq_length, n_features, 1))
                    for t in range(seq_length):
                        # æå–ç¬¬tä¸ªæ—¶é—´æ­¥çš„è¾“å…¥ç‰¹å¾å¯¹ç¬¬tä¸ªè¾“å‡ºçš„è´¡çŒ®
                        start_idx = t * n_features
                        end_idx = (t + 1) * n_features
                        shap_values_corrected[:, t, :, 0] = shap_values[:, start_idx:end_idx, t]
                    
                    shap_values = shap_values_corrected
                    n_outputs = 1
                    print(f"  å·²è½¬æ¢ä¸º: (n_instances, seq_length, n_features, n_outputs) = {shap_values.shape}")
                elif dim2 == seq_length and dim3 == expected_flat:
                    # å¯èƒ½æ˜¯ (n_instances, n_outputs, n_features_flat)ï¼Œä½†n_outputs=seq_length
                    print(f"  æ£€æµ‹åˆ°æ ¼å¼: (n_instances, n_outputs, n_features_flat)")
                    print(f"  è¾“å‡ºæ•°: {dim2}, ç‰¹å¾æ•°: {dim3}")
                    n_outputs = dim2
                    shap_values = shap_values.reshape(actual_n_instances, n_outputs, seq_length, n_features)
                    shap_values = shap_values.transpose(0, 2, 3, 1)  # (n_instances, seq_length, n_features, n_outputs)
                elif dim3 == expected_flat:
                    # æ ‡å‡†æ ¼å¼: (n_instances, n_outputs, n_features_flat)
                    n_outputs = dim2
                    print(f"  æ ‡å‡†å¤šè¾“å‡ºæ¨¡å¼ï¼Œè¾“å‡ºæ•°: {n_outputs}")
                    print(f"  å±•å¹³ç‰¹å¾æ•°: {dim3}, æœŸæœ›: {expected_flat}")
                    
                    shap_values = shap_values.reshape(actual_n_instances, n_outputs, seq_length, n_features)
                    shap_values = shap_values.transpose(0, 2, 3, 1)  # (n_instances, seq_length, n_features, n_outputs)
                else:
                    raise ValueError(
                        f"æ— æ³•è§£æSHAPå€¼å½¢çŠ¶ {shap_values.shape}ã€‚"
                        f"æœŸæœ›ç‰¹å¾æ•°: {expected_flat} (seq_length={seq_length} * n_features={n_features}), "
                        f"ä½†å¾—åˆ°: dim1={dim1}, dim2={dim2}, dim3={dim3}"
                    )
            else:
                raise ValueError(f"æ„å¤–çš„SHAPå€¼å½¢çŠ¶: {shap_values.shape}, ç»´åº¦æ•°: {shap_values.ndim}")
            
            print(f"  Reshapeåå½¢çŠ¶: {shap_values.shape}\n")
        
        elif self.explainer_type in ["DeepExplainer", "GradientExplainer", "Explainer"] or hasattr(self.explainer, '__call__'):
            # è½¬æ¢ä¸ºæ¨¡å‹éœ€è¦çš„æ ¼å¼
            if self.seq_first:
                instances_for_shap = instances_tensor.permute(1, 0, 2).to(self.device)
            else:
                instances_for_shap = instances_tensor.to(self.device)
            
            # è®¡ç®—SHAPå€¼
            # shap.Explainerä½¿ç”¨__call__æ–¹æ³•ï¼Œæ—§çš„explainerä½¿ç”¨shap_valuesæ–¹æ³•
            if hasattr(self.explainer, 'shap_values'):
                shap_values = self.explainer.shap_values(instances_for_shap)
            else:
                # æ–°APIä½¿ç”¨__call__
                shap_values = self.explainer(instances_for_shap)
            
            # å¤„ç†shap.Explainerè¿”å›çš„Explanationå¯¹è±¡
            if hasattr(shap_values, 'values'):
                shap_values = shap_values.values
            
            # å¤„ç†SHAPå€¼æ ¼å¼
            # ç”±äºmodel_wrapperè¿”å›å±•å¹³çš„è¾“å‡º (batch, seq_len * output_size)
            # SHAPå€¼ä¹Ÿä¼šæ˜¯å±•å¹³çš„å½¢çŠ¶ (batch, seq_len * output_size, seq_len * n_features)
            # æˆ‘ä»¬éœ€è¦å°†å…¶reshapeä¸ºæ­£ç¡®çš„å½¢çŠ¶
            
            # è·å–å®ä¾‹çš„å½¢çŠ¶ä¿¡æ¯
            n_instances = instances_tensor.shape[0]
            seq_length = instances_tensor.shape[1]
            n_features = instances_tensor.shape[2]
            
            # è·å–è¾“å‡ºå¤§å°ï¼ˆä»æ¨¡å‹æˆ–èƒŒæ™¯æ•°æ®æ¨æ–­ï¼‰
            if hasattr(self.model_core, 'linearOut'):
                n_outputs = self.model_core.linearOut.out_features
            else:
                # å°è¯•ä»èƒŒæ™¯æ•°æ®æ¨æ–­
                n_outputs = 1  # é»˜è®¤å€¼
            
            # å°†SHAPå€¼è½¬æ¢ä¸ºnumpyæ•°ç»„
            if isinstance(shap_values, torch.Tensor):
                shap_values = shap_values.detach().cpu().numpy()
            elif isinstance(shap_values, list):
                shap_values = np.array(shap_values)
            
            # å¤„ç†SHAPå€¼å½¢çŠ¶
            if shap_values.ndim == 3:
                # (n_instances, seq_len * output_size, seq_len * n_features)
                # éœ€è¦reshapeä¸º (n_instances, seq_len, n_features, seq_len, output_size)
                # ç„¶åå–å¯¹è§’çº¿å…ƒç´  (æ¯ä¸ªæ—¶é—´æ­¥çš„è¾“å…¥å¯¹å¯¹åº”æ—¶é—´æ­¥è¾“å‡ºçš„è´¡çŒ®)
                shap_reshaped = shap_values.reshape(
                    n_instances, seq_length * n_outputs, seq_length, n_features
                )
                # å–å¯¹è§’çº¿ï¼šæ¯ä¸ªæ—¶é—´æ­¥çš„è¾“å…¥å¯¹å¯¹åº”æ—¶é—´æ­¥è¾“å‡ºçš„è´¡çŒ®
                # å½¢çŠ¶: (n_instances, seq_length, n_features, n_outputs)
                shap_values_final = np.zeros((n_instances, seq_length, n_features, n_outputs))
                for t in range(seq_length):
                    for o in range(n_outputs):
                        output_idx = t * n_outputs + o
                        shap_values_final[:, t, :, o] = shap_reshaped[:, output_idx, t, :]
                shap_values = shap_values_final
            elif shap_values.ndim == 2:
                # (n_instances, seq_len * n_features) - å¯èƒ½æ˜¯å•è¾“å‡ºæƒ…å†µ
                # å°è¯•reshape
                if shap_values.shape[1] == seq_length * n_features:
                    shap_values = shap_values.reshape(n_instances, seq_length, n_features, 1)
                else:
                    # å¦‚æœå½¢çŠ¶ä¸åŒ¹é…ï¼Œå¯èƒ½éœ€è¦å…¶ä»–å¤„ç†
                    # å‡è®¾æ˜¯æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„SHAPå€¼
                    shap_values_full = np.zeros((n_instances, seq_length, n_features, 1))
                    if shap_values.shape[1] == n_features:
                        shap_values_full[:, -1, :, 0] = shap_values
                    shap_values = shap_values_full
            else:
                # å…¶ä»–æƒ…å†µï¼Œå°è¯•è‡ªåŠ¨å¤„ç†
                # å¦‚æœå·²ç»æ˜¯æ­£ç¡®å½¢çŠ¶ï¼Œç›´æ¥ä½¿ç”¨
                if shap_values.ndim == 4 and shap_values.shape[1] == seq_length:
                    pass  # å·²ç»æ˜¯æ­£ç¡®å½¢çŠ¶
                else:
                    # æ— æ³•è‡ªåŠ¨å¤„ç†ï¼ŒæŠ›å‡ºé”™è¯¯
                    raise ValueError(
                        f"æ— æ³•å¤„ç†SHAPå€¼å½¢çŠ¶: {shap_values.shape}, "
                        f"æœŸæœ›å½¢çŠ¶: (n_instances, seq_length, n_features, n_outputs)"
                    )
        
        
        return shap_values
    
    def get_feature_importance(
        self,
        shap_values: np.ndarray,
        method: str = "mean_abs"
    ) -> np.ndarray:
        """
        è®¡ç®—ç‰¹å¾é‡è¦æ€§
        
        Parameters
        ----------
        shap_values : np.ndarray
            SHAPå€¼ï¼Œå½¢çŠ¶ä¸º (n_instances, seq_length, n_features, n_outputs)
        method : str
            èšåˆæ–¹æ³•ï¼š
            - "mean_abs": å¹³å‡ç»å¯¹SHAPå€¼
            - "sum_abs": ç»å¯¹SHAPå€¼ä¹‹å’Œ
            - "max_abs": æœ€å¤§ç»å¯¹SHAPå€¼
        
        Returns
        -------
        np.ndarray
            ç‰¹å¾é‡è¦æ€§ï¼Œå½¢çŠ¶ä¸º (n_features, n_outputs) æˆ– (n_features,)
        """
        if method == "mean_abs":
            importance = np.mean(np.abs(shap_values), axis=(0, 1))  # åœ¨æ ·æœ¬å’Œæ—¶é—´æ­¥ç»´åº¦ä¸Šå¹³å‡
        elif method == "sum_abs":
            importance = np.sum(np.abs(shap_values), axis=(0, 1))  # åœ¨æ ·æœ¬å’Œæ—¶é—´æ­¥ç»´åº¦ä¸Šæ±‚å’Œ
        elif method == "max_abs":
            importance = np.max(np.abs(shap_values), axis=(0, 1))  # åœ¨æ ·æœ¬å’Œæ—¶é—´æ­¥ç»´åº¦ä¸Šå–æœ€å¤§å€¼
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„èšåˆæ–¹æ³•: {method}")
        
        return importance
    
    def get_temporal_importance(
        self,
        shap_values: np.ndarray,
        method: str = "mean_abs"
    ) -> np.ndarray:
        """
        è®¡ç®—æ—¶é—´æ­¥é‡è¦æ€§
        
        Parameters
        ----------
        shap_values : np.ndarray
            SHAPå€¼ï¼Œå½¢çŠ¶ä¸º (n_instances, seq_length, n_features, n_outputs)
        method : str
            èšåˆæ–¹æ³•ï¼š
            - "mean_abs": å¹³å‡ç»å¯¹SHAPå€¼
            - "sum_abs": ç»å¯¹SHAPå€¼ä¹‹å’Œ
            - "max_abs": æœ€å¤§ç»å¯¹SHAPå€¼
        
        Returns
        -------
        np.ndarray
            æ—¶é—´æ­¥é‡è¦æ€§ï¼Œå½¢çŠ¶ä¸º (seq_length, n_outputs) æˆ– (seq_length,)
        """
        if method == "mean_abs":
            importance = np.mean(np.abs(shap_values), axis=(0, 2))  # åœ¨æ ·æœ¬å’Œç‰¹å¾ç»´åº¦ä¸Šå¹³å‡
        elif method == "sum_abs":
            importance = np.sum(np.abs(shap_values), axis=(0, 2))  # åœ¨æ ·æœ¬å’Œç‰¹å¾ç»´åº¦ä¸Šæ±‚å’Œ
        elif method == "max_abs":
            importance = np.max(np.abs(shap_values), axis=(0, 2))  # åœ¨æ ·æœ¬å’Œç‰¹å¾ç»´åº¦ä¸Šå–æœ€å¤§å€¼
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„èšåˆæ–¹æ³•: {method}")
        
        return importance


def analyze_lstm_with_shap(
    model: nn.Module,
    background_data: np.ndarray,
    instances: np.ndarray,
    feature_names: Optional[List[str]] = None,
    device: torch.device = None,
    explainer_type: str = "KernelExplainer",
    which_first_tensor: str = "sequence",
    save_path: Optional[str] = None,
) -> Dict:
    """
    å¯¹LSTMæ¨¡å‹è¿›è¡ŒSHAPåˆ†æçš„ä¾¿æ·å‡½æ•°
    
    Parameters
    ----------
    model : nn.Module
        è®­ç»ƒå¥½çš„LSTMæ¨¡å‹
    background_data : np.ndarray
        èƒŒæ™¯æ•°æ®ï¼Œå½¢çŠ¶ä¸º (n_samples, seq_length, n_features)
    instances : np.ndarray
        è¦è§£é‡Šçš„å®ä¾‹ï¼Œå½¢çŠ¶ä¸º (n_instances, seq_length, n_features)
    feature_names : List[str], optional
        ç‰¹å¾åç§°åˆ—è¡¨
    device : torch.device, optional
        è®¡ç®—è®¾å¤‡
    explainer_type : str
        è§£é‡Šå™¨ç±»å‹
    which_first_tensor : str
        å¼ é‡æ ¼å¼
    save_path : str, optional
        ä¿å­˜è·¯å¾„
    
    Returns
    -------
    Dict
        åŒ…å«SHAPå€¼å’Œé‡è¦æ€§åˆ†æç»“æœçš„å­—å…¸
    """
    if device is None:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    analyzer = LSTMSHAPAnalyzer(
        model=model,
        background_data=background_data,
        device=device,
        explainer_type=explainer_type,
        which_first_tensor=which_first_tensor,
    )
    
    # è®¡ç®—SHAPå€¼
    shap_values = analyzer.explain(instances)
    
    # è®¡ç®—ç‰¹å¾é‡è¦æ€§
    feature_importance = analyzer.get_feature_importance(shap_values, method="mean_abs")
    
    # è®¡ç®—æ—¶é—´æ­¥é‡è¦æ€§
    temporal_importance = analyzer.get_temporal_importance(shap_values, method="mean_abs")
    
    # å‡†å¤‡ç‰¹å¾åç§°
    if feature_names is None:
        n_features = shap_values.shape[2]
        feature_names = [f"Feature_{i}" for i in range(n_features)]
    
    results = {
        "shap_values": shap_values,
        "feature_importance": feature_importance,
        "temporal_importance": temporal_importance,
        "feature_names": feature_names,
    }
    
    if save_path is not None:
        import pickle
        with open(save_path, "wb") as f:
            pickle.dump(results, f)
        print(f"SHAPç»“æœå·²ä¿å­˜åˆ°: {save_path}")
    
    return results


def compute_shap_contributions_to_excel(
    shap_values: np.ndarray,
    feature_names: List[str],
    output_path: str,
    output_names: Optional[List[str]] = None,
) -> None:
    """
    å°†SHAPå€¼è´¡çŒ®åº¦ç»Ÿè®¡ç»“æœè¾“å‡ºåˆ°Excelæ–‡ä»¶
    
    Parameters
    ----------
    shap_values : np.ndarray
        SHAPå€¼ï¼Œå½¢çŠ¶ä¸º (n_samples, seq_length, n_features, n_outputs)
    feature_names : List[str]
        ç‰¹å¾åç§°åˆ—è¡¨
    output_path : str
        è¾“å‡ºExcelæ–‡ä»¶è·¯å¾„
    output_names : List[str], optional
        è¾“å‡ºå˜é‡åç§°åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤åç§°
    """
    n_samples, seq_length, n_features, n_outputs = shap_values.shape
    
    # å‡†å¤‡è¾“å‡ºå˜é‡åç§°
    if output_names is None:
        output_names = [f"Output_{i}" for i in range(n_outputs)]
    
    # åˆ›å»ºExcelå†™å…¥å™¨ï¼Œè‡ªåŠ¨æ£€æµ‹å¯ç”¨çš„å¼•æ“
    # ä¼˜å…ˆä½¿ç”¨ openpyxlï¼Œå¦‚æœä¸å¯ç”¨åˆ™å°è¯• xlsxwriter
    excel_engine = None
    try:
        import openpyxl
        excel_engine = 'openpyxl'
    except ImportError:
        try:
            import xlsxwriter
            excel_engine = 'xlsxwriter'
        except ImportError:
            raise ImportError(
                "éœ€è¦å®‰è£… Excel å†™å…¥åº“ã€‚è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤ä¹‹ä¸€ï¼š\n"
                "  pip install openpyxl\n"
                "  æˆ–\n"
                "  pip install xlsxwriter"
            )
    
    # åˆ›å»ºExcelå†™å…¥å™¨
    with pd.ExcelWriter(output_path, engine=excel_engine) as writer:
        for output_idx, output_name in enumerate(output_names):
            # æå–å½“å‰è¾“å‡ºçš„SHAPå€¼
            shap_output = shap_values[:, :, :, output_idx]  # (n_samples, seq_length, n_features)
            
            # è®¡ç®—æ¯ä¸ªæ—¶æ®µæ¯ä¸ªç‰¹å¾çš„å¹³å‡è´¡çŒ®åº¦ï¼ˆè·¨æ ·æœ¬å¹³å‡ï¼‰
            contribution_matrix = np.mean(np.abs(shap_output), axis=0)  # (seq_length, n_features)
            
            # åˆ›å»ºDataFrame
            df = pd.DataFrame(
                contribution_matrix,
                index=[f"TimeStep_{t}" for t in range(seq_length)],
                columns=feature_names
            )
            
            # ä¿å­˜åˆ°Excelçš„sheet
            sheet_name = output_name[:31]  # Excel sheetåç§°é™åˆ¶ä¸º31ä¸ªå­—ç¬¦
            df.to_excel(writer, sheet_name=sheet_name, index=True)
            
            print(f"å·²ä¿å­˜ {output_name} çš„è´¡çŒ®åº¦çŸ©é˜µåˆ°Excelï¼Œå½¢çŠ¶: {contribution_matrix.shape}")
        
        # åˆ›å»ºä¸€ä¸ªæ±‡æ€»sheetï¼ŒåŒ…å«æ‰€æœ‰è¾“å‡ºçš„å¹³å‡è´¡çŒ®åº¦
        summary_data = []
        for output_idx, output_name in enumerate(output_names):
            shap_output = shap_values[:, :, :, output_idx]
            # è®¡ç®—æ¯ä¸ªç‰¹å¾åœ¨æ‰€æœ‰æ—¶æ®µçš„æ€»è´¡çŒ®åº¦
            feature_total_contrib = np.mean(np.abs(shap_output), axis=(0, 1))  # (n_features,)
            for feat_idx, feat_name in enumerate(feature_names):
                summary_data.append({
                    "Output": output_name,
                    "Feature": feat_name,
                    "Total_Contribution": feature_total_contrib[feat_idx],
                })
        
        summary_df = pd.DataFrame(summary_data)
        summary_df.to_excel(writer, sheet_name="Summary", index=False)
        print(f"å·²ä¿å­˜æ±‡æ€»ä¿¡æ¯åˆ°Excel")
    
    print(f"æ‰€æœ‰SHAPè´¡çŒ®åº¦ç»Ÿè®¡å·²ä¿å­˜åˆ°: {output_path}")

