# 可微分新安江模型运行机制详解

## 一、模型整体架构

可微分新安江模型（DplLstmXaj）采用**混合架构**，结合了深度学习（LSTM）和物理模型（新安江模型）：

```
输入数据 → LSTM → 新安江参数 → 新安江物理模型 → 流量输出
```

### 核心组件

1. **LSTM模块** (`SimpleLSTM`): 从输入特征学习生成新安江模型参数
2. **新安江物理模型** (`Xaj4Dpl`): 使用LSTM生成的参数进行物理过程模拟

---

## 二、数据处理流程

### 2.1 数据格式

数据通过 `FloodEventDplDataset` 处理，返回两种格式的数据：

- **x_train**: 未归一化的物理模型输入数据（原始单位，如mm/day）
  - 形状: `[sequence_length, batch_size, features]`
  - 特征: 降水(P)和潜在蒸散发(PET)
  
- **z_train**: 归一化的深度学习模型输入数据
  - 形状: `[sequence_length, batch_size, features]`
  - 特征: 归一化后的输入特征（可能包含静态属性）

- **y_train**: 未归一化的目标数据（流量）
  - 形状: `[sequence_length, batch_size, 1]`

### 2.2 时间步长配置

在配置文件中定义三个关键时间参数：

```python
"warmup_length": 0,        # 预热期长度（用于物理模型初始化状态）
"forecast_history": 30,    # 历史数据长度（输入序列长度）
"forecast_length": 1,      # 预测长度（输出序列长度）
```

**数据切片逻辑**（来自 `LongTermDataset.__getitem__`）:
```python
# 输入数据：包含warmup + forecast_history + forecast_length
x = self.x[basin, idx - warmup_length : idx + rho + horizon, :]

# 目标数据：从warmup结束开始，长度为forecast_history + forecast_length
y = self.y[basin, idx : idx + rho + horizon, :]
```

**示例**：
- warmup_length = 30天
- forecast_history = 30天  
- forecast_length = 1天
- 总输入长度 = 30 + 30 + 1 = 61天
- 实际预测目标 = 后31天（warmup后的30+1天）

---

## 三、前向传播流程

### 3.1 完整前向传播路径

```python
# 1. LSTM生成参数
gen = dl_model(z)  # z是归一化的输入 [seq_len, batch, features]
# gen形状: [seq_len, batch, n_params] (n_params=15个新安江参数)

# 2. 参数限制（确保在[0,1]范围内）
if param_func == "sigmoid":
    params_ = F.sigmoid(gen)
elif param_func == "clamp":
    params_ = torch.clamp(gen, min=0.0, max=1.0)

# 3. 取最后一个时间步的参数（或根据param_test_way选择）
params = params_[-1, :, :]  # [batch, n_params]

# 4. 新安江模型前向传播
q_sim = pb_model(x[:, :, :2], params)  # x只取前2个特征(P和PET)
```

### 3.2 LSTM参数生成

**LSTM结构** (`SimpleLSTM`):
```python
class SimpleLSTM(nn.Module):
    def __init__(self, input_size, output_size, hidden_size):
        self.linearIn = nn.Linear(input_size, hidden_size)
        self.lstm = nn.LSTM(hidden_size, hidden_size, 1)
        self.linearOut = nn.Linear(hidden_size, output_size)
    
    def forward(self, x):
        x0 = F.relu(self.linearIn(x))      # [seq, batch, hidden]
        out_lstm, (hn, cn) = self.lstm(x0)  # LSTM处理序列
        return self.linearOut(out_lstm)      # [seq, batch, n_params]
```

**输出**: 15个新安江参数（归一化到[0,1]）

### 3.3 参数反归一化

在 `Xaj4Dpl.forward()` 中，参数从[0,1]范围反归一化到物理范围：

```python
# 示例：K参数的反归一化
k = self.k_scale[0] + parameters[:, 0] * (self.k_scale[1] - self.k_scale[0])
# k_scale = [0.5, 1.5] 表示K参数的物理范围
```

**15个新安江参数**：
1. K: 蒸散发折算系数
2. B: 蓄水容量曲线指数
3. IM: 不透水面积比例
4. UM: 上层土壤蓄水容量
5. LM: 下层土壤蓄水容量
6. DM: 深层土壤蓄水容量
7. C: 深层蒸散发系数
8. SM: 自由水蓄水容量
9. EX: 自由水蓄水容量曲线指数
10. KI: 壤中流出流系数
11. KG: 地下径流出流系数
12. A: 单位线参数
13. THETA: 单位线参数
14. CI: 壤中流消退系数
15. CG: 地下径流消退系数

### 3.4 新安江模型物理过程

新安江模型按时间步逐步计算：

#### 步骤1: 产流计算 (`xaj_generation`)
```python
for i in range(inputs.shape[0]):  # 遍历每个时间步
    # 计算蒸发
    eu, el, ed = calculate_evap(lm, c, wu0, wl0, prcp, pet)
    e = eu + el + ed
    
    # 计算净降水
    pe = torch.clamp(prcp - e, min=0.0)
    
    # 计算产流量
    r, rim = calculate_prcp_runoff(b, im, wm, w0, pe)
    
    # 更新土壤含水量
    wu, wl, wd = calculate_w_storage(um, lm, dm, wu0, wl0, wd0, 
                                       eu, el, ed, prcp_difference, r)
```

#### 步骤2: 分水源 (`xaj_sources`)
```python
# 将产流量分为地表径流、壤中流、地下径流
(rs, ri, rg), (s, fr) = xaj_sources(pe, r, sm, ex, ki, kg, s0, fr0)
```

#### 步骤3: 汇流计算
```python
# 地表径流通过单位线汇流
conv_uh = KernelConv(a, theta, kernel_size)
qs_ = conv_uh(runoff_im + rss)

# 壤中流和地下径流通过线性水库
qi = linear_reservoir(ris_[i], ci, qi)  # 壤中流
qg = linear_reservoir(rgs_[i], cg, qg)  # 地下径流

# 总流量
qs[i, :] = qs_[i, :, 0] + qi + qg
```

### 3.5 预热期（Warmup）处理

如果设置了 `warmup_length > 0`：

```python
if warmup_length > 0:
    with torch.no_grad():  # 预热期不计算梯度
        # 使用预热期数据初始化模型状态
        p_and_e_warmup = p_and_e[0:warmup_length, :, :]
        _, _, *w0, s0, fr0, qi0, qg0 = cal_init_xaj4dpl(
            p_and_e_warmup, parameters, return_state=True
        )
```

预热期用于：
- 初始化土壤含水量（wu, wl, wd）
- 初始化自由水蓄量（s）
- 初始化产流面积（fr）
- 初始化线性水库状态（qi, qg）

---

## 四、反向传播机制

### 4.1 梯度计算流程

反向传播通过PyTorch的自动微分机制实现：

```python
# 训练循环（来自 torch_single_train）
for src, trg in data_loader:
    # 前向传播
    trg, output = model_infer(seq_first, device, model, src, trg)
    
    # 计算损失
    loss = compute_loss(trg, output, criterion)
    
    # 反向传播 - 关键步骤
    loss.backward()  # 自动计算所有参数的梯度
    
    # 更新参数
    opt.step()       # 根据梯度更新LSTM参数
    
    # 清空梯度
    model.zero_grad()
```

### 4.2 梯度传播路径

梯度从损失函数反向传播到LSTM：

```
损失函数 (loss)
    ↓
流量输出 (q_sim)
    ↓
新安江物理模型 (Xaj4Dpl)
    ↓ (梯度通过物理公式传播)
新安江参数 (params)
    ↓
参数限制函数 (sigmoid/clamp)
    ↓
LSTM输出 (gen)
    ↓
LSTM网络 (SimpleLSTM)
    ↓
LSTM参数 (权重和偏置)
```

### 4.3 关键：物理模型的可微性

新安江模型的所有计算都使用PyTorch的tensor操作，保证可微性：

- ✅ 所有数学运算（加减乘除、指数、对数）都是可微的
- ✅ 使用 `torch.clamp` 而不是 `torch.where`（某些情况下）来避免梯度问题
- ✅ 使用 `PRECISION = 1e-5` 来避免数值精度导致的梯度NaN

**示例**（来自 `xaj_sources`）:
```python
# 使用clamp确保梯度稳定
ss = torch.clamp(ss, max=sm - PRECISION)  # 避免除零和NaN
au = ms * (1.0 - (1.0 - ss / sm) ** (1.0 / (1.0 + ex)))
```

### 4.4 参数更新

只有LSTM的参数会被更新，新安江模型的参数范围（scale）是固定的：

```python
# LSTM参数（可训练）
self.linearIn.weight  # 可训练
self.lstm.weight_ih   # 可训练
self.linearOut.weight # 可训练

# 新安江参数范围（固定，不训练）
self.k_scale = [0.5, 1.5]  # 固定范围
self.b_scale = [0.1, 0.4]  # 固定范围
# ... 其他参数范围
```

---

## 五、输出新安江参数

### 5.1 参数提取

可以通过 `_extract_xaj_params` 函数提取当前时间步的新安江参数：

```python
def _extract_xaj_params(model, xs, device):
    # 1. 获取归一化输入
    z = xs[1]  # 归一化的输入
    
    # 2. LSTM生成参数
    gen = model.dl_model(z)
    
    # 3. 应用限制函数
    if model.param_func == "sigmoid":
        params_ = F.sigmoid(gen)
    
    # 4. 取最后一个时间步
    params = params_[-1, :, :]  # [batch, n_params]
    
    # 5. 反归一化到物理范围
    denormalized_params = {}
    for i, param_name in enumerate(param_names):
        scale = param_scales[param_name]
        denormalized_value = scale[0] + params[:, i] * (scale[1] - scale[0])
        denormalized_params[param_name] = denormalized_value
    
    return denormalized_params
```

### 5.2 参数使用方式

根据 `param_test_way` 配置，可以选择不同的参数使用策略：

- **"final"**: 使用最后一个时间步的参数（默认）
- **"mean_time"**: 使用所有时间步参数的平均值
- **"mean_basin"**: 使用所有流域最后一个时间步参数的平均值

---

## 六、数据流总结

### 6.1 训练时的数据流

```
原始数据
  ↓
数据加载器 (DataLoader)
  ↓
FloodEventDplDataset.__getitem__()
  ↓
返回: (x_train, z_train), y_train
  ↓
DplLstmXaj.forward(x, z)
  ↓
  ├─→ SimpleLSTM(z) → params [归一化]
  └─→ Xaj4Dpl(x, params) → q_sim
  ↓
计算损失 loss = criterion(q_sim, y_train)
  ↓
loss.backward() → 梯度传播
  ↓
opt.step() → 更新LSTM参数
```

### 6.2 输入输出维度

**输入维度**:
- `x`: `[seq_len, batch, 2]` - 未归一化的P和PET
- `z`: `[seq_len, batch, n_features]` - 归一化的输入特征

**中间维度**:
- `gen`: `[seq_len, batch, 15]` - LSTM输出的15个参数
- `params`: `[batch, 15]` - 最后一个时间步的参数

**输出维度**:
- `q_sim`: `[seq_len, batch, 1]` - 模拟流量

---

## 七、关键代码位置

### 7.1 模型定义
- **LSTM模型**: `hydromodel_dl/models/lstm.py` - `SimpleLSTM`
- **新安江模型**: `hydromodel_dl/models/dpl4xaj.py` - `Xaj4Dpl`
- **混合模型**: `hydromodel_dl/models/dpl4xaj.py` - `DplLstmXaj`

### 7.2 数据处理
- **数据集**: `hydromodel_dl/datasets/data_sets.py` - `FloodEventDplDataset`
- **数据配置**: `hydromodel_dl/configs/config.py` - `default_config_file()`

### 7.3 训练流程
- **训练循环**: `hydromodel_dl/trainers/train_utils.py` - `torch_single_train()`
- **模型推理**: `hydromodel_dl/trainers/train_utils.py` - `model_infer()`
- **损失计算**: `hydromodel_dl/trainers/train_utils.py` - `compute_loss()`

### 7.4 物理过程
- **产流计算**: `hydromodel_dl/models/dpl4xaj.py` - `xaj_generation()`
- **分水源**: `hydromodel_dl/models/dpl4xaj.py` - `xaj_sources()`
- **线性水库**: `hydromodel_dl/models/dpl4xaj.py` - `linear_reservoir()`

---

## 八、常见问题

### Q1: 为什么需要两个输入（x和z）？
**A**: 
- `x`是未归一化的物理数据，直接用于新安江模型（需要物理单位）
- `z`是归一化的数据，用于LSTM训练（归一化有助于训练稳定性）

### Q2: 参数是如何随时间变化的？
**A**: LSTM在每个时间步都会输出参数，但默认只使用最后一个时间步的参数。可以通过修改 `lstm_pbm` 函数来使用不同时间步的参数。

### Q3: 预热期是否参与训练？
**A**: 不参与。预热期使用 `torch.no_grad()` 计算，只用于初始化状态，不计算梯度。

### Q4: 如何确保梯度不会消失或爆炸？
**A**: 
- 使用 `torch.clamp` 限制数值范围
- 使用 `PRECISION` 避免除零
- 参数限制在[0,1]范围内，然后反归一化

### Q5: 新安江模型的参数是固定的吗？
**A**: 参数**范围**是固定的（如K在[0.5, 1.5]），但参数**值**是LSTM动态生成的，会随输入变化。

---

## 九、总结

可微分新安江模型的核心思想是：

1. **LSTM学习参数**: 从输入特征中学习新安江模型的参数
2. **物理模型计算**: 使用学习到的参数进行物理过程模拟
3. **端到端训练**: 通过反向传播同时优化LSTM和物理模型的表现
4. **可解释性**: 可以提取和查看学习到的新安江参数

这种混合架构结合了深度学习的灵活性和物理模型的可解释性，是当前水文建模的前沿方法。

